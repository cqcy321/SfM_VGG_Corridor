

#define CERES_FOUND 1
#include <opencv2/core.hpp>
#include <opencv2/sfm.hpp>
#include <opencv2/viz.hpp>

#include <iostream>
#include <sstream>
#include <fstream>
#include <string>

using namespace std;
using namespace cv;
using namespace cv::sfm;

bool loadPoints3D(const std::string &filename, vector<Vec3d>& points3d)
{
    ifstream f;
    f.open(filename.c_str());

    if(f.eof())
    return false;

    int count = 0;
    double a[6];
    while(!f.eof())
    {
        count ++;
        string snode;
        getline(f,snode);
        stringstream ssnode;
        ssnode << snode;

        for(int i=0;i<6;i++){
            ssnode >> a[i];
        }
        if(count==40)continue;
        points3d.push_back(-Vec3d(a[0],a[1],a[2]));
        points3d.push_back(-Vec3d(a[3],a[4],a[5]));

    }
    cout<<points3d.size()<<endl;
    return true;

}

bool loadCamera(const std::string &filename, vector<Matx33d> &Rs_est, vector<Vec3d> &ts_est)
{
    ifstream f;
    f.open(filename.c_str());

    if(f.eof())
    return false;

    int count = 0;
    double a[12];
    while(!f.eof())
    {
        count ++;
        int j=0;
        string snode;
        stringstream ssnode;
        getline(f,snode);
        ssnode << snode;
        for(int i=0;i<4;i++){
            ssnode >> a[j++];
        }
        ssnode.clear();
        getline(f,snode);
        ssnode << snode;
        for(int i=0;i<4;i++){
            ssnode >> a[j++];
        }
        getline(f,snode);
        ssnode.clear();
        ssnode << snode;
        for(int i=0;i<4;i++){
            ssnode >> a[j++];
        }

//        if(count==40)continue;
        Rs_est.push_back(Matx33d(-a[0],-a[1],-a[2],a[4],a[5],a[6],-a[8],-a[9],-a[10]));
        ts_est.push_back(Vec3d(a[3],a[7],a[11]));

    }
//    cout<<points3d.size()<<endl;
    return true;

}

static void help() {
  cout
      << "\n------------------------------------------------------------------\n"
      << " This program shows the camera trajectory reconstruction capabilities\n"
      << " in the OpenCV Structure From Motion (SFM) module.\n"
      << " \n"
      << " Usage:\n"
      << "        example_sfm_trajectory_reconstruction <path_to_tracks_file> <f> <cx> <cy>\n"
      << " where: is the tracks file absolute path into your system. \n"
      << " \n"
      << "        The file must have the following format: \n"
      << "        row1 : x1 y1 x2 y2 ... x36 y36 for track 1\n"
      << "        row2 : x1 y1 x2 y2 ... x36 y36 for track 2\n"
      << "        etc\n"
      << " \n"
      << "        i.e. a row gives the 2D measured position of a point as it is tracked\n"
      << "        through frames 1 to 36.  If there is no match found in a view then x\n"
      << "        and y are -1.\n"
      << " \n"
      << "        Each row corresponds to a different point.\n"
      << " \n"
      << "        f  is the focal lenght in pixels. \n"
      << "        cx is the image principal point x coordinates in pixels. \n"
      << "        cy is the image principal point y coordinates in pixels. \n"
      << "------------------------------------------------------------------\n\n"
      << endl;
}


/* Build the following structure data
 *
 *            frame1           frame2           frameN
 *  track1 | (x11,y11) | -> | (x12,y12) | -> | (x1N,y1N) |
 *  track2 | (x21,y11) | -> | (x22,y22) | -> | (x2N,y2N) |
 *  trackN | (xN1,yN1) | -> | (xN2,yN2) | -> | (xNN,yNN) |
 *
 *
 *  In case a marker (x,y) does not appear in a frame its
 *  values will be (-1,-1).
 */

void parser_2D_tracks(const string &_filename, std::vector<Mat> &points2d )
{
  ifstream myfile(_filename.c_str());

  if (!myfile.is_open())
  {
    cout << "Unable to read file: " << _filename << endl;
    exit(0);

  } else {

    double x, y;
    string line_str;
    int n_frames = 0, n_tracks = 0;

    // extract data from text file

    vector<vector<Vec2d> > tracks;
    for ( ; getline(myfile,line_str); ++n_tracks)
    {
      istringstream line(line_str);

      vector<Vec2d> track;
      for ( n_frames = 0; line >> x >> y; ++n_frames)
      {
        if ( x > 0 && y > 0)
          track.push_back(Vec2d(x,y));
        else
          track.push_back(Vec2d(-1));
      }
      tracks.push_back(track);
    }

    // embed data in reconstruction api format

    for (int i = 0; i < n_frames; ++i)
    {
      Mat_<double> frame(2, n_tracks);

      for (int j = 0; j < n_tracks; ++j)
      {
        frame(0,j) = tracks[j][i][0];
        frame(1,j) = tracks[j][i][1];
      }
      points2d.push_back(Mat(frame));
    }

    myfile.close();
  }

}


/* Keyboard callback to control 3D visualization
 */

bool camera_pov = false;

void keyboard_callback(const viz::KeyboardEvent &event, void* cookie)
{
  if ( event.action == 0 &&!event.symbol.compare("s") )
    camera_pov = !camera_pov;
}


/* Sample main code
 */

int main(int argc, char** argv)
{
  // Read input parameters
  bool is_projective = true;
  vector<Matx33d> Rs_est;
  vector<Vec3d> ts_est;
//-17.3952
//    cv::Matx33d K(517.8237 , 0, 358.8203, 0 -528.3985, 251.1046, 0, 0, 1);
  Matx33d K = Matx33d( 1914, 0, 640,
                       0, 1914, 360,
                       0, 0,  1);
  for (int num =0;num<11;num++){
      char camfile[40];
      sprintf(camfile,"camera/cameras%.3d.txt",num);
        loadCamera(camfile,Rs_est,ts_est);

    }
    vector<Vec3d> point_cloud_est;
  loadPoints3D("Corridor/bt.l3d",point_cloud_est);
  // Print output

  cout << "\n----------------------------\n" << endl;
  cout << "Reconstruction: " << endl;
  cout << "============================" << endl;
//  cout << "Estimated 3D points: " << points3d_estimated.size() << endl;
//  cout << "Estimated cameras: " << Rs_est.size() << endl;
//  cout << "Refined intrinsics: " << endl << K << endl << endl;

  cout << "3D Visualization: " << endl;
  cout << "============================" << endl;


  /// Create 3D windows
  viz::Viz3d window_est("Estimation Coordinate Frame");
             window_est.setBackgroundColor(viz::Color::white()); // black by default
             window_est.registerKeyboardCallback(&keyboard_callback);

  // Create the pointcloud
  cout << "Recovering points  ... ";

  // recover estimated points3d

//  for (int i = 0; i < points3d_estimated.size(); ++i)
//    point_cloud_est.push_back(Vec3f(points3d_estimated[i]));

  cout << "[DONE]" << endl;


  /// Recovering cameras
  cout << "Recovering cameras ... ";

  vector<Affine3d> path_est;
  for (size_t i = 0; i < Rs_est.size(); ++i)
    path_est.push_back(Affine3d(Rs_est[i],ts_est[i]));

  cout << "[DONE]" << endl;

  /// Add cameras
  cout << "Rendering Trajectory  ... ";

  /// Wait for key 'q' to close the window
  cout << endl << "Press:                       " << endl;
  cout <<         " 's' to switch the camera pov" << endl;
  cout <<         " 'q' to close the windows    " << endl;


  if (1)// path_est.size() > 0 )
  {
    // animated trajectory
    int idx = 0, forw = -1, n = static_cast<int>(path_est.size());

    while(!window_est.wasStopped())
    {

        int N=point_cloud_est.size();
      /// Render points as 3D cubes
      for (size_t i = 0; i < N; i+=2)
      {

                  char buffer[50];
                  sprintf (buffer, "%d", static_cast<int>(i));
          window_est.showWidget(buffer,viz::WLine(point_cloud_est[i],point_cloud_est[i+1],viz::Color::black()));
//        Vec3d point = point_cloud_est[i];
//        Affine3d point_pose(Mat::eye(3,3,CV_64F), point);

//        char buffer[50];
//        sprintf (buffer, "%d", static_cast<int>(i));

//        viz::WCube cube_widget(Point3f(0.1,0.1,0.0), Point3f(0.0,0.0,-0.1), true, viz::Color::blue());
//                   cube_widget.setRenderingProperty(viz::LINE_WIDTH, 2.0);
//        window_est.showWidget("Cube"+string(buffer), cube_widget, point_pose);
      }
//    cout<<idx<<endl;
//          window_est.showWidget("cyl0", viz::WLine(Vec3d(-0.5, 0.5, -0.5), Vec3d(0.5, 0.5, -0.5),  viz::Color::brown()));
    window_est.showWidget("coos", viz::WCoordinateSystem());

    for (size_t i = 0; i < n; i++)
    {
      Affine3d cam_pose = path_est[i];

      viz::WCameraPosition cpw; // Coordinate axes
//      viz::WCoordinateSystem cam_co();
      viz::WCameraPosition cpw_frustum(K, 0.3, viz::Color::yellow()); // Camera frustum

      char buffer[50],buffer1[50];
      sprintf (buffer, "%d", static_cast<int>(i));
      sprintf (buffer1, "cam%d", static_cast<int>(i));
      if ( camera_pov )
        window_est.setViewerPose(cam_pose);
      else
      {
        // render complete trajectory
        window_est.showWidget("cameras_frames_and_lines_est", viz::WTrajectory(path_est, viz::WTrajectory::PATH, 1.0, viz::Color::green()));

        window_est.showWidget(buffer, cpw, cam_pose);
        window_est.showWidget(buffer1, cpw_frustum, cam_pose);
      }
}

      // frame rate 1s
      window_est.spinOnce(1, true);
      window_est.removeAllWidgets();
    }

  }

  return 0;
}

